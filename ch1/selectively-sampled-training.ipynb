{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ch. 1: Selectively Sampled Training","metadata":{}},{"cell_type":"markdown","source":"## 0. General Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\n!pip install wget\nimport wget\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\nimport matplotlib.pyplot as plt\nimport cv2\n\n\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# '''\n# Borrowed from this user:\n# https://stackoverflow.com/questions/66288078/any-easy-way-to-get-imagenet-dataset-for-training-custom-model-in-tensorflow\n\n# Images are stored in the following manner:\n# tiny-imagenet-200/train/<class>/images/<image_ID>.jpeg\n# '''\n\n# from zipfile import ZipFile\n\n# url = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n# tiny_imgdataset = wget.download('http://cs231n.stanford.edu/tiny-imagenet-200.zip', out = os.getcwd())\n# for file in tqdm(os.listdir(os.getcwd())):\n#     if file.endswith(\".zip\"):\n#         zip_ = ZipFile(file)\n#         zip_.extractall()\n#     else:\n#         print(\"Not found.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TinyImageNetData(tf.keras.utils.Sequence):\n\n    def __init__(self, \n                 directory, \n                 batch_size,\n                 model = None,\n                 train_split = 0.8,\n                 img_size = (256, 256),\n                 random_seed = 42):\n        \n        '''\n        Assumes directory is structured like \n        <class>/images/<image_ID>\n        '''\n        \n        self.image_files = []\n        self.labels = []\n        self.id2class = {}\n        \n        self.valid_loss = []\n        self.valid_acc = []\n        \n        # save all files\n        for ind, img_class in enumerate(os.listdir(directory)):\n            self.id2class[ind] = img_class\n            img_class_folder = os.path.join(directory, img_class, 'images')\n            for img_name in os.listdir(img_class_folder):\n                self.image_files.append(os.path.join(img_class_folder, img_name))\n                self.labels.append(ind) # we can just use an ordinal encoding\n        \n        # shuffle order\n        joined = list(zip(self.image_files, self.labels))\n        random.seed(random_seed)\n        random.shuffle(joined)\n        self.image_files, self.labels = zip(*joined)\n        \n        # train-test split\n        split_ind = int(train_split * len(self.image_files))\n        self.X_train = self.image_files[:split_ind]\n        self.y_train = self.labels[:split_ind]\n        self.X_valid = self.image_files[:split_ind]\n        self.y_valid = self.labels[:split_ind]\n        \n        # calculate and store stats\n        self.batch_size = batch_size\n        self.num_samples = len(self.image_files)\n        self.train_size = len(self.X_train)\n        self.train_batches = self.train_size // batch_size\n        self.valid_size = len(self.X_valid)\n        self.valid_batches = self.valid_size // batch_size\n        self.img_size = img_size\n\n    def __len__(self):\n        return self.train_batches\n\n    def __getitem__(self, idx):\n        imgs, labels = [], []\n        for ind in range(idx*self.batch_size, (idx+1)*self.batch_size):\n            img = plt.imread(self.X_train[ind])\n            img = cv2.resize(img, self.img_size)\n            if len(img.shape) == 2: # grayscale, no color depth\n                img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) # cvt to color\n            imgs.append(img)\n            labels.append(self.y_train[ind])\n        return np.stack(imgs) / 255, np.expand_dims(np.stack(labels), 1)\n    \n    def get_valid_item(self, idx):\n        imgs, labels = [], []\n        for ind in range(idx*self.batch_size, (idx+1)*self.batch_size):\n            img = plt.imread(self.X_valid[ind])\n            img = cv2.resize(img, self.img_size)\n            if len(img.shape) == 2: # grayscale, no color depth\n                img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) # cvt to color\n            imgs.append(img)\n            labels.append(self.y_valid[ind])\n        return np.stack(imgs) / 255, np.expand_dims(np.stack(labels), 1)\n    \n    def validate(self):\n        scce = keras.losses.SparseCategoricalCrossentropy()\n        acc = keras.metrics.Accuracy()\n        scce_sum, acc_sum = 0, 0\n        for idx in tqdm(range(self.valid_batches)):\n            imgs, labels = self.get_valid_item(idx)\n            pred = self.model.predict(imgs)\n            scce_sum += scce(labels, pred) / self.valid_batches\n            acc.update_state(labels, np.argmax(pred, axis=1))\n            acc_sum += acc.result().numpy() / self.valid_batches\n            acc.reset_state()\n        return scce_sum, acc_sum\n    \n    def on_epoch_end(self):\n        scce, acc = self.validate()\n        self.valid_loss.append(scce)\n        self.valid_acc.append(acc)\n        print(f'\\tSCCE: {np.round(scce,2)} | Acc: {np.round(acc, 2)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize data. For now, we won't provide a model.","metadata":{}},{"cell_type":"code","source":"data = TinyImageNetData(directory = 'tiny-imagenet-200/train', \n                        batch_size = 32,\n                        img_size = (256, 256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a, b = data[8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10), dpi=400)\nfor row in range(8):\n    for col in range(8):\n        plt.subplot(8, 8, row*8 + col + 1)\n        plt.imshow(a[row*8 + col])\n        plt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Training a Baseline Model","metadata":{}},{"cell_type":"code","source":"base_model = keras.applications.InceptionV3(\n    include_top = True,\n    weights = None,\n    input_shape = (256, 256, 3),\n    classes = 200,\n    classifier_activation = \"softmax\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add base_model to dataset for validation\ndata.model = base_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.compile(optimizer='adam', \n                   loss='sparse_categorical_crossentropy',\n                   metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_history = keras.callbacks.History()\nbase_model.fit(data, epochs=5, callbacks=[base_history])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(base_history.history['loss'], label='Training')\nplt.plot(data.valid_loss, linestyle='--', label='Validation')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(base_history.history['accuracy'], label='Training')\nplt.plot(data.valid_acc, linestyle='--', label='Validation')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Calculating Difficulty Scores","metadata":{}},{"cell_type":"code","source":"scores = []\nscce = keras.losses.SparseCategoricalCrossentropy(reduction='none')\nfor batch_idx in tqdm(range(len(data))):\n    imgs, labels = data[batch_idx]\n    pred = base_model.predict(imgs)\n    losses = scce(labels, pred).numpy()\n    scores.extend(losses.astype(np.float16).tolist())\nscores = np.array(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del base_model # no longer needed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6), dpi=400)\nplt.hist(scores, bins=100, alpha=0.5)\nplt.ylabel('Count')\nplt.xlabel('Difficulty Score (Loss)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Probabilistic Sampling","metadata":{}},{"cell_type":"code","source":"class ProbSampleImageNetData(TinyImageNetData):\n    \n    curr_sample = 0\n    scores = None\n    operative_train_size = 2500\n    \n    def __len__(self):\n        return self.operative_train_size\n    \n    def __getitem__(self, idx):\n        '''\n        Requires user to attach self.scores\n        '''\n        \n        imgs, labels = [], []\n        counter = 0\n        while counter < self.batch_size:\n            if np.random.uniform() < self.th_probs[self.curr_sample]:\n                img = plt.imread(self.X_train[self.curr_sample])\n                img = cv2.resize(img, self.img_size)\n                if len(img.shape) == 2: # grayscale, no color depth\n                    img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) # cvt to color\n                imgs.append(img)\n                labels.append(self.y_train[self.curr_sample])\n                counter += 1\n            self.curr_sample = (self.curr_sample + 1) % self.train_size\n        \n        return np.stack(imgs) / 255, np.expand_dims(np.stack(labels), 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_data = ProbSampleImageNetData(directory = 'tiny-imagenet-200/train', \n                                    batch_size = 32,\n                                    img_size = (256, 256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def s2tp(s): return np.exp(-s) # return 1 - np.exp(-s)\nprobs_data.th_probs = s2tp(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6), dpi=400)\nplt.hist(s2tp(scores), bins=100, alpha=0.5)\nplt.ylabel('Count')\nplt.xlabel('Theoretical Probability')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a, b = probs_data[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_model = keras.applications.InceptionV3(\n    include_top = True,\n    weights = None,\n    input_shape = (256, 256, 3),\n    classes = 200,\n    classifier_activation = \"softmax\"\n)\nprobs_data.model = probs_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_model.compile(optimizer='adam', \n                    loss='sparse_categorical_crossentropy',\n                    metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_history = keras.callbacks.History()\nprobs_model.fit(probs_data, epochs=5, callbacks=[probs_history])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(probs_history.history['loss'], label='Training')\nplt.plot(probs_data.valid_loss, linestyle='--', label='Validation')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(probs_history.history['accuracy'], label='Training')\nplt.plot(probs_data.valid_acc, linestyle='--', label='Validation')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del probs_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Deterministic Sampling","metadata":{}},{"cell_type":"code","source":"dets_data = TinyImageNetData(directory = 'tiny-imagenet-200/train', \n                             batch_size = 32,\n                             img_size = (256, 256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentile = 80\nthresh = np.percentile(scores, percentile)\nind_mask = np.squeeze(np.argwhere(scores < thresh))\ndets_data.X_train = np.array(dets_data.X_train)[ind_mask]\ndets_data.y_train = np.array(dets_data.y_train)[ind_mask]\ndets_data.train_size = len(dets_data.X_train)\ndets_data.train_batches = dets_data.train_batches // dets_data.batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dets_model = keras.applications.InceptionV3(\n    include_top = True,\n    weights = None,\n    input_shape = (256, 256, 3),\n    classes = 200,\n    classifier_activation = \"softmax\"\n)\ndets_data.model = dets_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dets_model.compile(optimizer='adam', \n                   loss='sparse_categorical_crossentropy',\n                   metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dets_history = keras.callbacks.History()\ndets_model.fit(dets_data, epochs=5, callbacks=[dets_history])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(dets_history.history['loss'], label='Training')\nplt.plot(dets_data.valid_loss, linestyle='--', label='Validation')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(dets_history.history['accuracy'], label='Training')\nplt.plot(dets_data.valid_acc, linestyle='--', label='Validation')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Comparison","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(base_history.history['loss'], label='Prob. Sampling')\nplt.plot(probs_history.history['loss'], linestyle='--', label='Prob. Sampling')\nplt.plot(dets_history.history['loss'], linestyle='dotted', label='Det. Sampling')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Train Loss')\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(data.valid_perf, label='Prob. Sampling')\nplt.plot(probs_data.valid_perf, linestyle='--', label='Prob. Sampling')\nplt.plot(dets_data.valid_perf, linestyle='dotted', label='Det. Sampling')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Valid. Loss')\nplt.plot()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(base_history.history['accuracy'], label='Prob. Sampling')\nplt.plot(probs_history.history['accuracy'], linestyle='--', label='Prob. Sampling')\nplt.plot(dets_history.history['accuracy'], linestyle='dotted', label='Det. Sampling')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Train Accuracy')\nplt.plot()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5), dpi=400)\nplt.plot(data.valid_acc, label='Prob. Sampling')\nplt.plot(probs_data.valid_acc, linestyle='--', label='Prob. Sampling')\nplt.plot(dets_data.valid_acc, linestyle='dotted', label='Det. Sampling')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Valid. Accuracy')\nplt.plot()","metadata":{},"execution_count":null,"outputs":[]}]}